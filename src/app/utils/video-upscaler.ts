import { Resolution, resolutionSettings } from "./resolutions";
// Dynamically import ffmpeg only when needed (mp4 conversion) – we pin to 0.11.x which exposes createFFmpeg + fetchFile
type FFmpegModule = typeof import("@ffmpeg/ffmpeg");

interface VideoInfo {
  width: number;
  height: number;
  duration: number;
  fileSize: number;
}

interface UpscaleOptions {
  resolution: Resolution;
  bitrate: number; // in Mbps
  format?: "webm" | "mp4"; // mp4 support via ffmpeg.wasm
}

export async function getVideoInfo(file: File): Promise<VideoInfo> {
  return new Promise((resolve, reject) => {
    const video = document.createElement("video");
    video.preload = "metadata";

    video.onloadedmetadata = () => {
      URL.revokeObjectURL(video.src);
      resolve({
        width: video.videoWidth,
        height: video.videoHeight,
        duration: video.duration,
        fileSize: file.size,
      });
    };

    video.onerror = () => {
      URL.revokeObjectURL(video.src);
      reject(new Error("Failed to load video metadata"));
    };

    video.src = URL.createObjectURL(file);
  });
}

export function formatFileSize(bytes: number): string {
  if (bytes === 0) return "0 Bytes";

  const k = 1024;
  const sizes = ["Bytes", "KB", "MB", "GB"];
  const i = Math.floor(Math.log(bytes) / Math.log(k));

  return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + " " + sizes[i];
}

export async function upscaleVideo(
  file: File,
  options: UpscaleOptions,
  onProgress: (progress: number) => void,
  abortSignal?: AbortSignal
): Promise<{ blob: Blob; fileSize: number }> {
  console.log("Starting video upscale process", { file, options });
  return new Promise((resolve, reject) => {
    const sourceVideo = document.createElement("video");
    sourceVideo.src = URL.createObjectURL(file);
    sourceVideo.muted = true;

    const targetDimensions = resolutionSettings[options.resolution];
    console.log("Target dimensions:", targetDimensions);

    const canvas = document.createElement("canvas");
    const ctx = canvas.getContext("2d", { alpha: false });

    if (!ctx) {
      console.error("Failed to get canvas context");
      reject(new Error("Failed to get canvas context"));
      return;
    }

    // Handle abort signal
    let isAborted = false;
    let mediaRecorder: MediaRecorder | null = null;

    if (abortSignal) {
      if (abortSignal.aborted) {
        console.log("Operation was already aborted");
        reject(new Error("Operation cancelled"));
        return;
      }
      abortSignal.addEventListener("abort", () => {
        console.log("Operation aborted by user");
        isAborted = true;
        sourceVideo.pause();
        if (mediaRecorder && mediaRecorder.state !== "inactive") {
          mediaRecorder.stop();
        }
        reject(new Error("Operation cancelled"));
      });
    }

    sourceVideo.onloadedmetadata = () => {
      console.log("Video metadata loaded", {
        width: sourceVideo.videoWidth,
        height: sourceVideo.videoHeight,
        duration: sourceVideo.duration,
      });

      // Decide which side to fit based on orientation to keep original aspect ratio with NO black bars.
      let newWidth: number;
      let newHeight: number;

      if (sourceVideo.videoWidth >= sourceVideo.videoHeight) {
        // Landscape – fit width to target width
        const scale = targetDimensions.width / sourceVideo.videoWidth;
        newWidth = targetDimensions.width;
        newHeight = Math.round(sourceVideo.videoHeight * scale);
      } else {
        // Portrait – fit height to target height
        const scale = targetDimensions.height / sourceVideo.videoHeight;
        newHeight = targetDimensions.height;
        newWidth = Math.round(sourceVideo.videoWidth * scale);
      }

      // Resize canvas to the exact scaled dimensions (no letterboxing)
      canvas.width = newWidth;
      canvas.height = newHeight;

      // Create MediaRecorder with appropriate settings
      const videoStream = canvas.captureStream();
      console.log("Created canvas stream");

      // Fix TypeScript error with type assertion
      const audioStream = (
        (
          sourceVideo as HTMLVideoElement & {
            captureStream?: () => MediaStream;
          }
        ).captureStream?.() || new MediaStream()
      ).getAudioTracks()[0];

      if (audioStream) {
        console.log("Audio track found and added");
        videoStream.addTrack(audioStream);
      } else {
        console.log("No audio track found");
      }

      // We always record WebM (browser-supported); MP4 will be generated by transcoding later.
      const mimeType = "video/webm;codecs=vp9,opus";

      try {
        mediaRecorder = new MediaRecorder(videoStream, {
          mimeType,
          videoBitsPerSecond: options.bitrate * 1000000,
        });
        console.log("MediaRecorder created successfully");
      } catch (err) {
        console.error("Failed to create MediaRecorder:", err);
        reject(
          new Error(
            "Failed to initialize video recording. Your browser may not support the required codecs."
          )
        );
        return;
      }

      const chunks: Blob[] = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          chunks.push(e.data);
          console.log("Received chunk of size:", e.data.size);
        }
      };

      mediaRecorder.onerror = (event) => {
        console.error("MediaRecorder error:", event);
        reject(new Error("Error during recording: " + event.error));
      };

      mediaRecorder.onstop = () => {
        console.log("MediaRecorder stopped");
        if (isAborted) return;
        URL.revokeObjectURL(sourceVideo.src);
        const webmBlob = new Blob(chunks, { type: "video/webm" });
        console.log("Created final blob of size:", webmBlob.size);

        // If target is MP4, transcode using ffmpeg.wasm
        if (options.format === "mp4") {
          (async () => {
            if (isAborted) return; // Don't start FFmpeg if aborted
            const { createFFmpeg, fetchFile }: FFmpegModule = await import(
              "@ffmpeg/ffmpeg"
            );
            const ffmpeg = createFFmpeg({ log: true });
            await ffmpeg.load();
            if (isAborted) return;

            await ffmpeg.FS(
              "writeFile",
              "input.webm",
              await fetchFile(webmBlob)
            );

            // Higher quality encoding: slow preset + CRF 18 (visually lossless)
            await ffmpeg.run(
              "-i",
              "input.webm",
              "-c:v",
              "libx264",
              "-preset",
              "slow",
              "-crf",
              "18",
              "-c:a",
              "aac",
              "-b:a",
              "192k",
              "output.mp4"
            );

            const data = ffmpeg.FS("readFile", "output.mp4");
            const mp4Blob = new Blob([new Uint8Array(data.buffer)], {
              type: "video/mp4",
            });
            resolve({ blob: mp4Blob, fileSize: mp4Blob.size });
          })().catch((err) => {
            console.error("FFmpeg MP4 conversion failed:", err);
            // Fallback to returning WebM
            resolve({ blob: webmBlob, fileSize: webmBlob.size });
          });
        } else {
          // Return WebM directly
          resolve({ blob: webmBlob, fileSize: webmBlob.size });
        }
      };

      sourceVideo.play().catch((err) => {
        console.error("Failed to play source video:", err);
        reject(new Error("Failed to play source video"));
      });

      mediaRecorder.start(1000);
      console.log("MediaRecorder started");

      let lastProcessedTime = 0;
      const videoDuration = sourceVideo.duration;

      function processFrame() {
        if (isAborted) return;
        if (sourceVideo.ended || sourceVideo.paused) {
          console.log("Video ended or paused, stopping recorder");
          if (mediaRecorder && mediaRecorder.state !== "inactive") {
            mediaRecorder.stop();
          }
          return;
        }

        ctx?.drawImage(sourceVideo, 0, 0, newWidth, newHeight);

        const currentProgress = (sourceVideo.currentTime / videoDuration) * 100;
        if (
          Math.floor(currentProgress) >
          Math.floor((lastProcessedTime / videoDuration) * 100)
        ) {
          console.log("Progress:", Math.floor(currentProgress));
          onProgress(Math.floor(currentProgress));
          lastProcessedTime = sourceVideo.currentTime;
        }

        requestAnimationFrame(processFrame);
      }

      processFrame();
    };

    sourceVideo.onerror = (e) => {
      console.error("Video loading error:", e);
      URL.revokeObjectURL(sourceVideo.src);
      reject(new Error("Error loading video file"));
    };
  });
}
